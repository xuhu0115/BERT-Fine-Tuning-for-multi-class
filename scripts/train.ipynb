{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m219.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "file_path = \"../data/功能段分类参考1230.xlsx\"\n",
    "df = pd.read_excel(file_path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Research Question 研究问题功能段</th>\n",
       "      <th>Transition I 背景类过渡段</th>\n",
       "      <th>Transition II 项目类过渡段</th>\n",
       "      <th>Transition III 文献类过渡段</th>\n",
       "      <th>Research Desgin 研究设计功能段</th>\n",
       "      <th>Research Finding 研究发现功能段</th>\n",
       "      <th>Marginal Contribution 边际贡献功能段（汇总）</th>\n",
       "      <th>Section 章节安排功能段</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Across a few prohibitive miles: The impact of ...</td>\n",
       "      <td>1：\\nTo lift nearly 100 million impoverished ru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2：\\nThe government launched the APRP to facili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5：\\nA conceptual framework is thus adopted tha...</td>\n",
       "      <td>7：\\nIn addition to a positive ATT, we document...</td>\n",
       "      <td>10：\\nThis study is related to a wide range of ...</td>\n",
       "      <td>13：\\nThe remainder of the paper is organized a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armed groups: Competition and political violence</td>\n",
       "      <td>1：\\nThe proliferation of armed groups is often...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2：\\nAn additional armed group is likely to inc...</td>\n",
       "      <td>4：\\nThis paper provides quasi-experimental evi...</td>\n",
       "      <td>6：\\nWe estimate that an additional active arme...</td>\n",
       "      <td>10：\\nWe contribute to various strands of the l...</td>\n",
       "      <td>13：\\nThe remainder of the paper is structured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict and reciprocity: A study with Palesti...</td>\n",
       "      <td>1：\\nReciprocity, as the practice of behaving t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2：\\nReciprocity can support cooperation: it ca...</td>\n",
       "      <td>5：\\nIn this paper, we present an observational...</td>\n",
       "      <td>7：\\nComparing individuals going to the same sc...</td>\n",
       "      <td>8：\\nA strength of our paper is that it intenti...</td>\n",
       "      <td>12：\\nThe remaining of the paper is as follows....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exposure to collective gender-based violence c...</td>\n",
       "      <td>1：\\nWhy do so many men harm their intimate par...</td>\n",
       "      <td>3：\\nThis paper studies the causal long-run imp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:\\nMost existing research into the drivers of...</td>\n",
       "      <td>5：\\nTheoretically, it is a priori unclear whet...</td>\n",
       "      <td>10：\\nOur central result is that a man ’s expos...</td>\n",
       "      <td>12：\\nOur theoretical arguments and empirical f...</td>\n",
       "      <td>17：\\nThe rest of the paper is organized as fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Learning by searching: Spatial mismatches and ...</td>\n",
       "      <td>1:\\nUnemployment rates for young job-seekers r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2：\\nIn an attempt to identify the labour marke...</td>\n",
       "      <td>3:\\nOur experiment takes place in Johannesburg...</td>\n",
       "      <td>6：\\nWe find that providing job search subsidie...</td>\n",
       "      <td>8：\\nOur findings sit at the intersection of se...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "1  Across a few prohibitive miles: The impact of ...   \n",
       "2   Armed groups: Competition and political violence   \n",
       "3  Conflict and reciprocity: A study with Palesti...   \n",
       "4  Exposure to collective gender-based violence c...   \n",
       "5  Learning by searching: Spatial mismatches and ...   \n",
       "\n",
       "                           Research Question 研究问题功能段  \\\n",
       "1  1：\\nTo lift nearly 100 million impoverished ru...   \n",
       "2  1：\\nThe proliferation of armed groups is often...   \n",
       "3  1：\\nReciprocity, as the practice of behaving t...   \n",
       "4  1：\\nWhy do so many men harm their intimate par...   \n",
       "5  1:\\nUnemployment rates for young job-seekers r...   \n",
       "\n",
       "                                 Transition I 背景类过渡段  \\\n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  3：\\nThis paper studies the causal long-run imp...   \n",
       "5                                                NaN   \n",
       "\n",
       "                                Transition II 项目类过渡段  \\\n",
       "1  2：\\nThe government launched the APRP to facili...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                               Transition III 文献类过渡段  \\\n",
       "1                                                NaN   \n",
       "2  2：\\nAn additional armed group is likely to inc...   \n",
       "3  2：\\nReciprocity can support cooperation: it ca...   \n",
       "4  2:\\nMost existing research into the drivers of...   \n",
       "5  2：\\nIn an attempt to identify the labour marke...   \n",
       "\n",
       "                             Research Desgin 研究设计功能段  \\\n",
       "1  5：\\nA conceptual framework is thus adopted tha...   \n",
       "2  4：\\nThis paper provides quasi-experimental evi...   \n",
       "3  5：\\nIn this paper, we present an observational...   \n",
       "4  5：\\nTheoretically, it is a priori unclear whet...   \n",
       "5  3:\\nOur experiment takes place in Johannesburg...   \n",
       "\n",
       "                            Research Finding 研究发现功能段  \\\n",
       "1  7：\\nIn addition to a positive ATT, we document...   \n",
       "2  6：\\nWe estimate that an additional active arme...   \n",
       "3  7：\\nComparing individuals going to the same sc...   \n",
       "4  10：\\nOur central result is that a man ’s expos...   \n",
       "5  6：\\nWe find that providing job search subsidie...   \n",
       "\n",
       "                   Marginal Contribution 边际贡献功能段（汇总）  \\\n",
       "1  10：\\nThis study is related to a wide range of ...   \n",
       "2  10：\\nWe contribute to various strands of the l...   \n",
       "3  8：\\nA strength of our paper is that it intenti...   \n",
       "4  12：\\nOur theoretical arguments and empirical f...   \n",
       "5  8：\\nOur findings sit at the intersection of se...   \n",
       "\n",
       "                                     Section 章节安排功能段  \n",
       "1  13：\\nThe remainder of the paper is organized a...  \n",
       "2  13：\\nThe remainder of the paper is structured ...  \n",
       "3  12：\\nThe remaining of the paper is as follows....  \n",
       "4  17：\\nThe rest of the paper is organized as fol...  \n",
       "5                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = []\n",
    "\n",
    "# Iterate through rows of the original DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    title = row['Title']\n",
    "    research_question = row['Research Question 研究问题功能段']\n",
    "    transition_i = row['Transition I 背景类过渡段']\n",
    "    transition_ii = row['Transition II 项目类过渡段']\n",
    "    transition_iii = row['Transition III 文献类过渡段']\n",
    "    research_design = row['Research Desgin 研究设计功能段']\n",
    "    research_finding = row['Research Finding 研究发现功能段']\n",
    "    marginal_contribution = row['Marginal Contribution 边际贡献功能段（汇总）']\n",
    "    section = row['Section 章节安排功能段']\n",
    "\n",
    "    # Append each row as a dictionary to the result_data list\n",
    "    result_data.append({'sentences': title, 'name': 'Title'})\n",
    "    result_data.append({'sentences': research_question, 'name': 'Research Question 研究问题功能段'})\n",
    "    result_data.append({'sentences': transition_i, 'name': 'Transition I 背景类过渡段'})\n",
    "    result_data.append({'sentences': transition_ii, 'name': 'Transition II 项目类过渡段'})\n",
    "    result_data.append({'sentences': transition_iii, 'name': 'Transition III 文献类过渡段'})\n",
    "    result_data.append({'sentences': research_design, 'name': 'Research Desgin 研究设计功能段'})\n",
    "    result_data.append({'sentences': research_finding, 'name': 'Research Finding 研究发现功能段'})\n",
    "    result_data.append({'sentences': marginal_contribution, 'name': 'Marginal Contribution 边际贡献功能段（汇总）'})\n",
    "    result_data.append({'sentences': section, 'name': 'Section 章节安排功能段'})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_data)\n",
    "\n",
    "# Save the result DataFrame to a new Excel file\n",
    "result_df.to_csv('../data/formatted_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Across a few prohibitive miles: The impact of ...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1：\\nTo lift nearly 100 million impoverished ru...</td>\n",
       "      <td>Research Question 研究问题功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Transition I 背景类过渡段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2：\\nThe government launched the APRP to facili...</td>\n",
       "      <td>Transition II 项目类过渡段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Transition III 文献类过渡段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5：\\nA conceptual framework is thus adopted tha...</td>\n",
       "      <td>Research Desgin 研究设计功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7：\\nIn addition to a positive ATT, we document...</td>\n",
       "      <td>Research Finding 研究发现功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10：\\nThis study is related to a wide range of ...</td>\n",
       "      <td>Marginal Contribution 边际贡献功能段（汇总）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13：\\nThe remainder of the paper is organized a...</td>\n",
       "      <td>Section 章节安排功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Armed groups: Competition and political violence</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1：\\nThe proliferation of armed groups is often...</td>\n",
       "      <td>Research Question 研究问题功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Transition I 背景类过渡段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Transition II 项目类过渡段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2：\\nAn additional armed group is likely to inc...</td>\n",
       "      <td>Transition III 文献类过渡段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4：\\nThis paper provides quasi-experimental evi...</td>\n",
       "      <td>Research Desgin 研究设计功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6：\\nWe estimate that an additional active arme...</td>\n",
       "      <td>Research Finding 研究发现功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10：\\nWe contribute to various strands of the l...</td>\n",
       "      <td>Marginal Contribution 边际贡献功能段（汇总）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13：\\nThe remainder of the paper is structured ...</td>\n",
       "      <td>Section 章节安排功能段</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Conflict and reciprocity: A study with Palesti...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1：\\nReciprocity, as the practice of behaving t...</td>\n",
       "      <td>Research Question 研究问题功能段</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences  \\\n",
       "0   Across a few prohibitive miles: The impact of ...   \n",
       "1   1：\\nTo lift nearly 100 million impoverished ru...   \n",
       "2                                                 NaN   \n",
       "3   2：\\nThe government launched the APRP to facili...   \n",
       "4                                                 NaN   \n",
       "5   5：\\nA conceptual framework is thus adopted tha...   \n",
       "6   7：\\nIn addition to a positive ATT, we document...   \n",
       "7   10：\\nThis study is related to a wide range of ...   \n",
       "8   13：\\nThe remainder of the paper is organized a...   \n",
       "9    Armed groups: Competition and political violence   \n",
       "10  1：\\nThe proliferation of armed groups is often...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  2：\\nAn additional armed group is likely to inc...   \n",
       "14  4：\\nThis paper provides quasi-experimental evi...   \n",
       "15  6：\\nWe estimate that an additional active arme...   \n",
       "16  10：\\nWe contribute to various strands of the l...   \n",
       "17  13：\\nThe remainder of the paper is structured ...   \n",
       "18  Conflict and reciprocity: A study with Palesti...   \n",
       "19  1：\\nReciprocity, as the practice of behaving t...   \n",
       "\n",
       "                                 name  \n",
       "0                               Title  \n",
       "1           Research Question 研究问题功能段  \n",
       "2                 Transition I 背景类过渡段  \n",
       "3                Transition II 项目类过渡段  \n",
       "4               Transition III 文献类过渡段  \n",
       "5             Research Desgin 研究设计功能段  \n",
       "6            Research Finding 研究发现功能段  \n",
       "7   Marginal Contribution 边际贡献功能段（汇总）  \n",
       "8                     Section 章节安排功能段  \n",
       "9                               Title  \n",
       "10          Research Question 研究问题功能段  \n",
       "11                Transition I 背景类过渡段  \n",
       "12               Transition II 项目类过渡段  \n",
       "13              Transition III 文献类过渡段  \n",
       "14            Research Desgin 研究设计功能段  \n",
       "15           Research Finding 研究发现功能段  \n",
       "16  Marginal Contribution 边际贡献功能段（汇总）  \n",
       "17                    Section 章节安排功能段  \n",
       "18                              Title  \n",
       "19          Research Question 研究问题功能段  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果值为nan，那么删除此条数据\n",
    "new_result_df  = result_df.dropna(subset=[\"sentences\"])\n",
    "len(new_result_df)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name                          labels                           \n",
    "Title                                0  \n",
    "Research Question 研究问题功能段            1  \n",
    "Research Finding 研究发现功能段             2  \n",
    "Research Desgin 研究设计功能段              3  \n",
    "Section 章节安排功能段                      4  \n",
    "Marginal Contribution 边际贡献功能段（汇总）   5  \n",
    "Transition III 文献类过渡段                6  \n",
    "Transition I 背景类过渡段                  7  \n",
    "Transition II 项目类过渡段                 8  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20523/4184537897.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_result_df['labels'] = new_result_df['name'].map(label_mapping)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义映射关系字典\n",
    "label_mapping = {\n",
    "    'Title': 0,\n",
    "    'Research Question 研究问题功能段': 1,\n",
    "    'Research Finding 研究发现功能段': 2,\n",
    "    'Research Desgin 研究设计功能段': 3,\n",
    "    'Section 章节安排功能段': 4,\n",
    "    'Marginal Contribution 边际贡献功能段（汇总）': 5,\n",
    "    'Transition III 文献类过渡段': 6,\n",
    "    'Transition I 背景类过渡段': 7,\n",
    "    'Transition II 项目类过渡段': 8\n",
    "}\n",
    "\n",
    "# 使用map函数将name映射为labels\n",
    "new_result_df['labels'] = new_result_df['name'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result_df.to_csv(\"../data/formatted_data_1230.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'name')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAETCAYAAAAveV3LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARMUlEQVR4nO3de5CddX3H8feHBOQSLkGWGG6uFtSiDmgjWmkrFqQoKExbW/AWHJTp1AteqkSltZ3pJTpWS0fHmVRQFIUC0gG0FZgodrCKbABFGjTKNRLCagsIeCHw7R/nSV2WDXs2ezn7g/drJnPOeZ5z+WazeefJc87zbKoKSVJ7thn0AJKkrWPAJalRBlySGmXAJalRBlySGmXAJalRBlzzVpITk1w56Dmk+cqASwOU5JYkRwx6DrXJgEtSowy4Bi7JvkkuTDKa5KdJPr6F+52e5PYk9yZZk+R3x6w7JMlIt25jko92y7dPcnb3vHcnuTrJkqnMkWSbJKcluTXJXUk+m2TXbt1hSdaPe57/36pO8tdJzuse87MkNyRZ1q37HLAfcEmS+5K8d/pfTT2RGHANVJIFwJeAW4FhYG/g3C3c/WrgYGB34AvA+Um279adDpxeVbsAvwGc1y1fDuwK7As8Gfgz4OdTnOPE7tdLgacDi4AJ/5HZgld1z7UbcPHmx1bV64HbgFdW1aKq+vAUnlMy4Bq4Q4C9gPdU1f1V9YuqmvCNy6o6u6p+WlWbquofgScBz+xWPwjsn2SPqrqvqr41ZvmTgf2r6qGqWlNV905xjtcCH62qm6rqPuB9wPFJFvb5e7yyqv69qh4CPgcc1OfjpMdkwDVo+wK3VtWmye6Y5N1J1ia5J8nd9Las9+hWnwQ8A7ix201yTLf8c8ClwLlJ7kjy4STbTnGOvehtmW92K7AQmHBXzATuHHP9AWD7KcRf2iIDrkG7HdhvsqB1+7tPBf4EWFxVuwH3AAGoqnVVdQKwJ/Ah4IIkO1XVg1X1N1V1IPBi4BjgDVOc4w7gqWNu7wdsAjYC9wM7jplzATA06e/61zwdqLaaAdegfRvYAKxMslP3puOhE9xvZ3rRHAUWJvkrYJfNK5O8LslQVT0M3N0tfijJS5M8twvrvfR2qTw0xTnOAd6Z5GlJFgF/D/xrt7X+A3pb1Ed3W/an0du106+N9ParS1NmwDVQ3X7hVwL703tDbz3wpxPc9VLgP+gF81bgF/S2mjc7CrghyX303tA8vqp+ATwFuIBevNcCXwfOnuIcZ9LbFfOfwM3da7+te9w9wJ8DnwJ+TG+L/BGfSpnEPwCndZ+Q+YspPE4i/kAHSWqTW+CS1CgDLkmNMuCS1CgDLkmNMuCS1Kg5PRpsjz32qOHh4bl8SUlq3po1a35SVY86QGxOAz48PMzIyMhcvqQkNS/JrRMtdxeKJDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSo+bdz+UbXvHlGXuuW1YePWPPJUnzjVvgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjZp3HyOcj/xoo6T5yC1wSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRnkyq4bN1Em2PMGW1Ca3wCWpUQZckhplwCWpUQZckhplwCWpUQZckhrVV8CTvDPJDUm+l+ScJNsn2T3J5UnWdZeLZ3tYSdKvTRrwJHsDbweWVdVzgAXA8cAKYHVVHQCs7m5LkuZIvwfyLAR2SPIgsCNwB/A+4LBu/VnAFcCpMzyfGuPBRdLcmXQLvKp+DHwEuA3YANxTVZcBS6pqQ3efDcCeszmoJOmR+tmFshg4FngasBewU5LX9fsCSU5OMpJkZHR0dOsnlSQ9Qj9vYh4B3FxVo1X1IHAh8GJgY5KlAN3lXRM9uKpWVdWyqlo2NDQ0U3NL0hNePwG/DXhRkh2TBDgcWAtcDCzv7rMcuGh2RpQkTWTSNzGr6qokFwDXAJuAa4FVwCLgvCQn0Yv8q2dzUEnSI/X1KZSq+iDwwXGLf0lva1ySNAAeiSlJjTLgktQoAy5JjTLgktQofyamHvdm6vB+8BB/zS9ugUtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKA3mkAfDgIs0Et8AlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVF9BTzJbkkuSHJjkrVJfjvJ7kkuT7Kuu1w828NKkn6t3y3w04GvVNWzgIOAtcAKYHVVHQCs7m5LkubIpAFPsgvwe8AZAFX1q6q6GzgWOKu721nAcbMzoiRpIv1sgT8dGAU+neTaJJ9KshOwpKo2AHSXe87inJKkcfoJ+ELg+cAnq+p5wP1MYXdJkpOTjCQZGR0d3coxJUnj9RPw9cD6qrqqu30BvaBvTLIUoLu8a6IHV9WqqlpWVcuGhoZmYmZJEn0EvKruBG5P8sxu0eHAfwMXA8u7ZcuBi2ZlQknShBb2eb+3AZ9Psh1wE/BGevE/L8lJwG3Aq2dnREnSRPoKeFVdByybYNXhMzqNJKlvHokpSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY3q94caS3qcG17x5Rl7rltWHj1jz6UtcwtckhplwCWpUQZckhplwCWpUb6JKWlem6k3Vx+Pb6y6BS5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5Jjeo74EkWJLk2yZe627snuTzJuu5y8eyNKUkabypb4KcAa8fcXgGsrqoDgNXdbUnSHOkr4En2AY4GPjVm8bHAWd31s4DjZnQySdJj6ncL/J+A9wIPj1m2pKo2AHSXe070wCQnJxlJMjI6OjqdWSVJY0wa8CTHAHdV1ZqteYGqWlVVy6pq2dDQ0NY8hSRpAv38QIdDgVcleQWwPbBLkrOBjUmWVtWGJEuBu2ZzUEnSI026BV5V76uqfapqGDge+GpVvQ64GFje3W05cNGsTSlJepTpfA58JfCyJOuAl3W3JUlzZEo/E7OqrgCu6K7/FDh85keSJPXDIzElqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVGTBjzJvkm+lmRtkhuSnNIt3z3J5UnWdZeLZ39cSdJmC/u4zybg3VV1TZKdgTVJLgdOBFZX1cokK4AVwKmzN6okzQ/DK748I89zy8qjp/X4SbfAq2pDVV3TXf8ZsBbYGzgWOKu721nAcdOaRJI0JVPaB55kGHgecBWwpKo2QC/ywJ5beMzJSUaSjIyOjk5zXEnSZn0HPMki4IvAO6rq3n4fV1WrqmpZVS0bGhramhklSRPoK+BJtqUX789X1YXd4o1JlnbrlwJ3zc6IkqSJ9PMplABnAGur6qNjVl0MLO+uLwcumvnxJElb0s+nUA4FXg9cn+S6btn7gZXAeUlOAm4DXj0rE0qSJjRpwKvqSiBbWH34zI4jSeqXR2JKUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqOmFfAkRyX5fpIfJlkxU0NJkia31QFPsgD4BPBy4EDghCQHztRgkqTHNp0t8EOAH1bVTVX1K+Bc4NiZGUuSNJlU1dY9MPlj4KiqelN3+/XAC6vqrePudzJwcnfzmcD3t37cR9gD+MkMPddMcab+OFP/5uNcztSfmZzpqVU1NH7hwmk8YSZY9qh/DapqFbBqGq8z8YsnI1W1bKafdzqcqT/O1L/5OJcz9WcuZprOLpT1wL5jbu8D3DG9cSRJ/ZpOwK8GDkjytCTbAccDF8/MWJKkyWz1LpSq2pTkrcClwALgzKq6YcYmm9yM75aZAc7UH2fq33ycy5n6M+szbfWbmJKkwfJITElqlAGXpEYZcElqVBMBT/KsJKcm+eckp3fXf3PQc81H3dfq8CSLxi0/aoAzHZLkBd31A5O8K8krBjXPRJJ8dtAzjJXkd7qv05EDnOGFSXbpru+Q5G+SXJLkQ0l2HeBcb0+y7+T3nDtJtkvyhiRHdLdfk+TjSd6SZNtZe935/iZmklOBE+gdqr++W7wPvY8tnltVKwc125YkeWNVfXoAr/t24C3AWuBg4JSquqhbd01VPX8AM32Q3vlyFgKXAy8ErgCOAC6tqr8bwEzjP+4a4KXAVwGq6lUDmOnbVXVId/3N9P4c/w04ErhkEN/nSW4ADuo+cbYKeAC4ADi8W/6Hcz1TN9c9wP3Aj4BzgPOranQQs4yZ6fP0vsd3BO4GFgEX0vtapaqWz8oLV9W8/gX8ANh2guXbAesGPd8WZr5tQK97PbCouz4MjNCLOMC1A5xpQfeNfS+wS7d8B+C7A5rpGuBs4DDgJd3lhu76SwY007Vjrl8NDHXXdwKuH9BMa8d+zcatu24QM23+WtHbe3AkcAYwCnwFWA7sPKCZvttdLgQ2Agu625nN7/PpHEo/Vx4G9gJuHbd8abduIJJ8d0urgCVzOcsYC6rqPoCquiXJYcAFSZ7KxKc+mAubquoh4IEkP6qqe7v5fp5kUH9+y4BTgA8A76mq65L8vKq+PqB5ALZJsphemFLdFmVV3Z9k04Bm+t6Y/01+J8myqhpJ8gzgwQHNBFBV9TBwGXBZt4vi5fT+p/4R4FHnDJkD23QHNO5Eb2NlV+B/gCcBs7YLpYWAvwNYnWQdcHu3bD9gf+CtW3rQHFgC/AHwv+OWB/ivuR8HgDuTHFxV1wFU1X1JjgHOBJ47oJl+lWTHqnoA+K3NC7t9qAMJePeX/2NJzu8uNzL4vwu7Amvoff9UkqdU1Z3dexmD+sf3TcDpSU6jd1Kmbya5nd7fwzcNaCYY9/WoqgfpHQV+cZIdBjMSZwA30vvf5geA85PcBLyI3u7fWTHv94EDJNmG3ulr96b3h7ceuLrbshvUTGcAn66qKydY94Wqes0AZtqH3hbvnROsO7SqvjGAmZ5UVb+cYPkewNKqun6uZ5pglqOBQ6vq/YOeZbwkOwJLqurmAc6wM/B0ev/Ira+qjYOapZvnGVX1g0HOMJEkewFU1R1JdqP3Ps9tVfXtWXvNFgIuSXq0Jj5GKEl6NAMuSY0y4JLUKAMuSY0y4HrcSTKcZG2Sf0lyQ5LLukPB35zk6iTfSfLF7hMeJPlMkk8m+VqSm5K8JMmZ3XN8ZszzHpnkm0muSXL++NMVSHPNgOvx6gDgE1X1bHqHNv8RcGFVvaCqDqJ3uoGTxtx/MfD7wDuBS4CPAc8Gnpvk4O5jj6cBR1TvlAQjwLvm6jcjTWTQBy9Is+XmzQc00TtAZhh4TpK/BXajd66KS8fc/5KqqiTXAxs3fz69Ox/IML3z7xwIfCMJ9E7l8M1Z/11Ij8GA6/Fq7MFDD9E798pngOOq6jtJTqR3DpTx93943GMfpvf35CHg8qo6YZbmlabMXSh6ItkZ2NCdO+O1U3zst4BDk+wPvSMku3OCSANjwPVE8pfAVfROa3vjVB7YnVzqROCc7kRm3wKeNdMDSlPhofSS1Ci3wCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhr1fyKNIPEvA91CAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#new_result_df[\"name\"].value_counts()\n",
    "new_result_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('class count')\n",
    "plt.xlabel(\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句⼦⻓度分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "count     616.000000\n",
      "mean      226.209416\n",
      "std       208.944603\n",
      "min         3.000000\n",
      "25%        72.000000\n",
      "50%       163.000000\n",
      "75%       348.750000\n",
      "max      1130.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/IPython/core/magics/pylab.py:162: UserWarning: pylab import has clobbered these variables: ['title']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n",
      "/tmp/ipykernel_20523/4164117013.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_result_df['text_len'] = new_result_df['sentences'].apply(lambda x: len(x.split(' ')))\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "new_result_df['text_len'] = new_result_df['sentences'].apply(lambda x: len(x.split(' ')))\n",
    "print(new_result_df['text_len'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个句子平均226个单词组成，最长1130，最短3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of char count')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "_ = plt.hist(new_result_df['text_len'], bins=200)\n",
    "plt.xlabel('Text char count')\n",
    "plt.title(\"Histogram of char count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符分布统计\n",
    "\n",
    "统计每个单词出现的次数，将数据集中的所有句子进行拼接进而划分为单词，并统计每个单词的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17804\n",
      "('the', 7514)\n",
      "('subsidy.', 1)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_lines = ' '.join(list(new_result_df['sentences']))\n",
    "word_count = Counter(all_lines.split(\" \"))\n",
    "word_count = sorted(word_count.items(), key=lambda d:d[1], reverse = True)\n",
    "print(len(word_count))\n",
    "# 6869\n",
    "print(word_count[0])\n",
    "# ('3750', 7482224)\n",
    "print(word_count[-1])\n",
    "# ('3133', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中总共包括16089个单词，the出现最多6320，organize出现最少1次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 TF-IDF + 朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_result_df['sentences'], new_result_df['labels'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 特征提取\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # 选择最常见的5000个词\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练朴素贝叶斯分类器\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "y_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45161290322580644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36        18\n",
      "           1       0.31      0.69      0.43        16\n",
      "           2       0.27      1.00      0.43        14\n",
      "           3       0.50      0.06      0.10        18\n",
      "           4       1.00      1.00      1.00        13\n",
      "           5       0.68      0.76      0.72        17\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00        13\n",
      "           8       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.45       124\n",
      "   macro avg       0.42      0.41      0.34       124\n",
      "weighted avg       0.49      0.45      0.38       124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 评估模型性能\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Count Vectors + RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "train_df = pd.read_csv('../input/train_set.csv', sep='\\t', nrows=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data_path = \"/home/xuhu/project/littool/data/formatted_data_1230.csv\"  # 替换为你的数据路径\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "#train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Across a few prohibitive miles: The impact of ...</td>\n",
       "      <td>Title</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1：\\nTo lift nearly 100 million impoverished ru...</td>\n",
       "      <td>Research Question 研究问题功能段</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2：\\nThe government launched the APRP to facili...</td>\n",
       "      <td>Transition II 项目类过渡段</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5：\\nA conceptual framework is thus adopted tha...</td>\n",
       "      <td>Research Desgin 研究设计功能段</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7：\\nIn addition to a positive ATT, we document...</td>\n",
       "      <td>Research Finding 研究发现功能段</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  Across a few prohibitive miles: The impact of ...   \n",
       "1  1：\\nTo lift nearly 100 million impoverished ru...   \n",
       "2  2：\\nThe government launched the APRP to facili...   \n",
       "3  5：\\nA conceptual framework is thus adopted tha...   \n",
       "4  7：\\nIn addition to a positive ATT, we document...   \n",
       "\n",
       "                        name  labels  \n",
       "0                      Title       0  \n",
       "1  Research Question 研究问题功能段       1  \n",
       "2       Transition II 项目类过渡段       8  \n",
       "3    Research Desgin 研究设计功能段       3  \n",
       "4   Research Finding 研究发现功能段       2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 sentences 和 labels 列表\n",
    "sentences = data.sentences.values\n",
    "labels = data.labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载预训练的BERT模型到本地  \n",
    "git lfs install  \n",
    "git clone git@hf.co:bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练的BERT模型和tokenizer\n",
    "#model_name = 'bert-base-uncased'   #bert-base-uncased 不区分大小写\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/xuhu/project/littool/bert-base-uncased\")\n",
    "#model = BertForSequenceClassification.from_pretrained(\"/home/xuhu/project/littool/bert-base-uncased\", num_labels=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Across a few prohibitive miles: The impact of the Anti-Poverty Relocation Program in China\n",
      "Tokenized:  ['across', 'a', 'few', 'prohibit', '##ive', 'miles', ':', 'the', 'impact', 'of', 'the', 'anti', '-', 'poverty', 'relocation', 'program', 'in', 'china']\n",
      "Token IDs:  [2408, 1037, 2261, 23469, 3512, 2661, 1024, 1996, 4254, 1997, 1996, 3424, 1011, 5635, 18344, 2565, 1999, 2859]\n"
     ]
    }
   ],
   "source": [
    "# 输出原始句子\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# 将分词后的内容输出\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# 将每个词映射到词典下标\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  1483\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sent in sentences:\n",
    "\n",
    "    # 将文本分词，并添加 `[CLS]` 和 `[SEP]` 符号\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Across a few prohibitive miles: The impact of the Anti-Poverty Relocation Program in China\n",
      "Token IDs: tensor([  101,  2408,  1037,  2261, 23469,  3512,  2661,  1024,  1996,  4254,\n",
      "         1997,  1996,  3424,  1011,  5635, 18344,  2565,  1999,  2859,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# 将数据集分完词后存储到列表中\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # 输入文本\n",
    "                        add_special_tokens = True, # 添加 '[CLS]' 和 '[SEP]'\n",
    "                        max_length = 128,           # 填充 & 截断长度\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # 返回 attn. masks.\n",
    "                        return_tensors = 'pt',     # 返回 pytorch tensors 格式的数据\n",
    "                   )\n",
    "    \n",
    "    # 将编码后的文本加入到列表  \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # 将文本的 attention mask 也加入到 attention_masks 列表\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# 将列表转换为 tensor\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 输出第 1 行文本的原始和编码后的信息\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  554 training samples\n",
      "   62 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# 将输入数据合并为 TensorDataset 对象\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 计算训练集和验证集大小\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# 按照数据大小随机拆分训练集和测试集\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# 在 fine-tune 的训练中，BERT 作者建议小批量大小设为 16 或 32\n",
    "batch_size = 32\n",
    "\n",
    "# 为训练和验证集创建 Dataloader，对训练样本随机洗牌\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # 训练样本\n",
    "            sampler = RandomSampler(train_dataset), # 随机小批量\n",
    "            batch_size = batch_size, # 以小批量进行训练\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "# 验证集不需要随机化，这里顺序读取就好\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # 验证样本\n",
    "            sampler = SequentialSampler(val_dataset), # 顺序选取小批量\n",
    "            batch_size = batch_size ,\n",
    "            num_workers=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/xuhu/project/littool/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "#import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "#device = \"cpu\"\n",
    "# 加载 BertForSequenceClassification, 预训练 BERT 模型 + 顶层的线性分类层 \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"/home/xuhu/project/littool/bert-base-uncased\", # 小写的 12 层预训练模型\n",
    "    num_labels = 9, # 分类数 --2 表示二分类\n",
    "                    # 你可以改变这个数字，用于多分类任务  \n",
    "    output_attentions = False, # 模型是否返回 attentions weights.\n",
    "    output_hidden_states = False, # 模型是否返回所有隐层状态.\n",
    ")\n",
    "\n",
    "# 在 gpu 中运行该模型\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (9, 768)\n",
      "classifier.bias                                                 (9,)\n"
     ]
    }
   ],
   "source": [
    "# 将所有模型参数转换为一个列表\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 我认为 'W' 代表 '权重衰减修复\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# 训练 epochs。 BERT 作者建议在 2 和 4 之间，设大了容易过拟合 \n",
    "epochs = 10\n",
    "\n",
    "# 总的训练样本数\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 创建学习率调度器\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 根据预测结果和标签数据来计算准确率\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # 四舍五入到最近的秒\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # 格式化为 hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616, 616)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.46\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.56\n",
      "  Validation Loss: 1.47\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.57\n",
      "  Validation Loss: 1.27\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Validation Loss: 1.08\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.85\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation Loss: 0.99\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.73\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.71\n",
      "  Validation Loss: 0.94\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.71\n",
      "  Validation Loss: 0.91\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.73\n",
      "  Validation Loss: 0.82\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.73\n",
      "  Validation Loss: 0.83\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation Loss: 0.79\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation Loss: 0.78\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:00:44 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = \"cpu\"\n",
    "\n",
    "# 以下训练代码是基于 `run_glue.py` 脚本:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# 设定随机种子值，以确保输出是确定的\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 存储训练和评估的 loss、准确率、训练时长等统计指标, \n",
    "training_stats = []\n",
    "\n",
    "# 统计整个训练时长\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 统计单次 epoch 的训练时间\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 重置每次 epoch 的训练总 loss\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # 将模型设置为训练模式。这里并不是调用训练接口的意思\n",
    "    # dropout、batchnorm 层在训练和测试模式下的表现是不同的 (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # 训练集小批量迭代\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # 每经过40次迭代，就输出进度信息\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 准备输入数据，并将其拷贝到 gpu 中\n",
    "        # print(batch[0])\n",
    "        # print(batch[1])\n",
    "        # print(batch[2])\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # 每次计算梯度前，都需要将梯度清 0，因为 pytorch 的梯度是累加的\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # 前向传播\n",
    "        # 文档参见: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # 该函数会根据不同的参数，会返回不同的值。 本例中, 会返回 loss 和 logits -- 模型的预测结果\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        # 累加 loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 梯度裁剪，避免出现梯度爆炸情况\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "\n",
    "    # 平均训练误差\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # 单次 epoch 的训练时长\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # 完成一次 epoch 训练后，就对该模型的性能进行验证\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # 将输入数据加载到 gpu 中\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # 评估的时候不需要更新参数、计算梯度\n",
    "        with torch.no_grad():        \n",
    "            outputs= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        # 累加 loss\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # 将预测结果和 labels 加载到 cpu 中计算\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 计算准确率\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # 打印本次 epoch 的准确率\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # 统计本次 epoch 的 loss\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # 统计本次评估的时长\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # 记录本次 epoch 的所有统计信息\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save_pretrained(\"/home/xuhu/project/littool/models/bert_multiclass_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.460435</td>\n",
       "      <td>1.470940</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.193417</td>\n",
       "      <td>1.271089</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.019542</td>\n",
       "      <td>1.079537</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.852172</td>\n",
       "      <td>0.989849</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.726387</td>\n",
       "      <td>0.942658</td>\n",
       "      <td>0.711458</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.647827</td>\n",
       "      <td>0.911686</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.568660</td>\n",
       "      <td>0.815134</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.527695</td>\n",
       "      <td>0.826824</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.484222</td>\n",
       "      <td>0.794626</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.461443</td>\n",
       "      <td>0.783636</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1           1.460435     1.470940       0.564583       0:00:04         0:00:00\n",
       "2           1.193417     1.271089       0.565625       0:00:04         0:00:00\n",
       "3           1.019542     1.079537       0.693750       0:00:04         0:00:00\n",
       "4           0.852172     0.989849       0.678125       0:00:04         0:00:00\n",
       "5           0.726387     0.942658       0.711458       0:00:04         0:00:00\n",
       "6           0.647827     0.911686       0.712500       0:00:04         0:00:00\n",
       "7           0.568660     0.815134       0.727083       0:00:04         0:00:00\n",
       "8           0.527695     0.826824       0.727083       0:00:04         0:00:00\n",
       "9           0.484222     0.794626       0.758333       0:00:04         0:00:00\n",
       "10          0.461443     0.783636       0.758333       0:00:04         0:00:00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 保留 2 位小数\n",
    "#pd.set_option('precision', 2)\n",
    "\n",
    "# 加载训练统计到 DataFrame 中\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# 使用 epoch 值作为每行的索引\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# 展示表格数据\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# 绘图风格设置\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# 绘制学习曲线\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n",
      "Probabilities: [0.9502924680709839, 0.006528203375637531, 0.004167529754340649, 0.004886887967586517, 0.008691426366567612, 0.007228819653391838, 0.004670186433941126, 0.00602593831717968, 0.00750849349424243]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "# 加载微调后的模型和分词器\n",
    "model = BertForSequenceClassification.from_pretrained(\"/home/xuhu/project/littool/models/bert_multiclass_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/xuhu/project/littool/bert-base-uncased\")\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 输入文本进行预测\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    return predicted_class, probabilities[0].tolist()\n",
    "\n",
    "# 例子\n",
    "text_to_predict = \"Across a few prohibitive miles: The impact of the Anti-Poverty Relocation Program in China\"\n",
    "predicted_class, probabilities = predict(text_to_predict)\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probabilities: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, sentences, labels):\n",
    "#         self.sentences = sentences\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         encoding = self.tokenize_and_pad(self.sentences[idx], max_length=128)\n",
    "#         label = torch.tensor(self.labels[idx])\n",
    "#         return {'input_ids': encoding, 'labels': label}\n",
    "\n",
    "#     def tokenize_and_pad(self, sentence, max_length):\n",
    "#         tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sentence)))\n",
    "#         if len(tokens) > max_length:\n",
    "#             tokens = tokens[:max_length]\n",
    "#         else:\n",
    "#             tokens += ['[PAD]'] * (max_length - len(tokens))\n",
    "#         return tokenizer.convert_tokens_to_ids(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建数据集和数据加载器\n",
    "# train_dataset = CustomDataset(train_data['sentences'].tolist(), train_data['labels'].tolist())\n",
    "# val_dataset = CustomDataset(val_data['sentences'].tolist(), val_data['labels'].tolist())\n",
    "\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda batch: {'input_ids': pad_sequence([torch.tensor(item['input_ids']) for item in batch], batch_first=True), 'labels': torch.stack([item['labels'] for item in batch])})\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=lambda batch: {'input_ids': pad_sequence([torch.tensor(item['input_ids']) for item in batch], batch_first=True), 'labels': torch.stack([item['labels'] for item in batch])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhu/miniconda3/envs/peppi/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # 定义优化器和学习率调度器\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 62/62 [00:11<00:00,  5.50it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 62/62 [00:10<00:00,  5.75it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 62/62 [00:11<00:00,  5.22it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 62/62 [00:11<00:00,  5.44it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 62/62 [00:11<00:00,  5.61it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 62/62 [00:10<00:00,  5.65it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 62/62 [00:10<00:00,  5.72it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 62/62 [00:11<00:00,  5.31it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 62/62 [00:11<00:00,  5.48it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 62/62 [00:11<00:00,  5.48it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 62/62 [00:11<00:00,  5.57it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 62/62 [00:11<00:00,  5.47it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 62/62 [00:10<00:00,  6.11it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 62/62 [00:10<00:00,  5.74it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 62/62 [00:11<00:00,  5.61it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 62/62 [00:12<00:00,  5.13it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 62/62 [00:11<00:00,  5.44it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 62/62 [00:11<00:00,  5.42it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 62/62 [00:12<00:00,  5.15it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 62/62 [00:11<00:00,  5.53it/s]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7580645161290323\n",
      "Average Validation Loss: 0.8317735958844423\n",
      "Validation Perplexity: 2.2973897457122803\n"
     ]
    }
   ],
   "source": [
    "# # 训练模型\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# num_epochs = 20\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "#         try:\n",
    "#             inputs = {key: tensor.to(device) for key, tensor in batch.items() if key != 'labels'}\n",
    "#             labels = batch['labels'].to(device)\n",
    "#         except Exception as e:\n",
    "#             print(\"Error during training batch processing:\", e)\n",
    "#             print(\"Batch contents:\", batch)\n",
    "#             continue\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(**inputs, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#     # 在验证集上评估模型\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0  # 用于累积验证集上的损失\n",
    "#     val_preds = []\n",
    "#     val_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for val_batch in tqdm(val_loader, desc='Validation'):\n",
    "#             try:\n",
    "#                 val_inputs = {key: tensor.to(device) for key, tensor in val_batch.items() if key != 'labels'}\n",
    "#                 val_batch_labels = val_batch['labels'].to(device)\n",
    "#             except Exception as e:\n",
    "#                 print(\"Error during validation batch processing:\", e)\n",
    "#                 print(\"Batch contents:\", val_batch)\n",
    "#                 continue\n",
    "\n",
    "#             val_outputs = model(**val_inputs)\n",
    "#             logits = val_outputs.logits\n",
    "#             loss = model(**val_inputs, labels=val_batch_labels).loss  # 计算交叉熵损失\n",
    "#             val_loss += loss.item()  # 累积损失\n",
    "\n",
    "#             preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "#             val_preds.extend(preds)\n",
    "#             val_labels.extend(val_batch_labels.cpu().numpy())\n",
    "\n",
    "#     # 计算平均验证损失和困惑度\n",
    "#     average_val_loss = val_loss / len(val_loader)\n",
    "#     perplexity = torch.exp(torch.tensor(average_val_loss)).item()\n",
    "\n",
    "#     accuracy = accuracy_score(val_labels, val_preds)\n",
    "#     print(f'Validation Accuracy: {accuracy}')\n",
    "#     print(f'Average Validation Loss: {average_val_loss}')\n",
    "#     print(f'Validation Perplexity: {perplexity}')\n",
    "\n",
    "# # 保存模型\n",
    "# model.save_pretrained(\"/home/xuhu/project/littool/models/bert_multiclass_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8725,  0.5693, -0.5476,  0.1814, -0.8596,  0.1262,  0.1002,  0.2807,\n",
      "         -0.1814]], device='cuda:0')\n",
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# def predict(model, tokenizer, text, max_length=128):\n",
    "#     model.eval()\n",
    "    \n",
    "#     # 使用与训练时相同的方法来处理输入文本\n",
    "#     encoding = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "    \n",
    "#     # 将输入移到设备（GPU 或 CPU）\n",
    "#     inputs = {key: tensor.to(device) for key, tensor in encoding.items()}\n",
    "    \n",
    "#     # 使用模型进行预测\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "    \n",
    "#     # 获取预测的标签\n",
    "#     logits = outputs.logits\n",
    "#     print(logits)\n",
    "#     predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "#     return predicted_label\n",
    "\n",
    "# # 例子\n",
    "# input_text = \"Across a few prohibitive miles: The impact of the Anti-Poverty Relocation Program in China\"\n",
    "# predicted_label = predict(model, tokenizer, input_text)\n",
    "# print(f'Predicted Label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
